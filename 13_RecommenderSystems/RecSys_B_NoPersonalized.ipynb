{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>Updated January 2018 - This notebook was created by [Santi Seguí](https://ssegui.github.io/). </i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Non-Personalized recommeder systems</h3><br></div>\n",
    "\n",
    "<br>\n",
    "<p>A non-personalized recommender system is one that makes the same recommendations for everyone. </p>\n",
    "\n",
    "The simplest example is a retailer that shows the ten (or some number) most popular products on their homepage. <br>\n",
    "Some examples: <br><br>\n",
    "IMDB: MOVIE RANKING\n",
    "![alt IMDB](images/np1.png)\n",
    "\n",
    "___\n",
    "Amazon: Top Recommendations\n",
    "![alt Amazon](images/np2.png)\n",
    "___\n",
    "Amazon: Product Association\n",
    "![alt Amazon](images/np3.png)\n",
    "___\n",
    "Reedit: News Recommendations\n",
    "![alt Reedit](images/np4.png)\n",
    "\n",
    "\n",
    "<p><b>Several</b> cases but <b>two main</b> approaches\n",
    "\n",
    "1. Aggregated opinion recommenders\n",
    "2. Basic product association recommenders\n",
    "<br>\n",
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Aggregated opinion recommenders</h3><br></div>\n",
    "\n",
    "Usually, the problem posed as a learning to rank problem. But what seems to be straighfowrard becomes a really complicated question: <b>How do you rank your rated items and which logic to use to display them?</b>\n",
    "\n",
    "In order to score/rank items we first have to <b>understand the business case</b>. Of course, several factors plays a role. For instance, \n",
    "\n",
    "* Which information do we have about the items? Bought / Seen / Rated / ... \n",
    "* From how many users do we have the info for a particular item \n",
    "* How old is that info? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE: Non-Personalised Recommender using MovieLens Dataset\n",
    "We will work with the well known MovieLens dataset (http://grouplens.org/datasets/movielens/). This dataset was initially constructed to support participants in the Netflix Prize. Today, we can find several versions of this dataset with different amout of data, from 100k samples version to 20m sample version. Although performance on bigger dataset is expected to be better, we will work with the smallest dataset: MovieLens 100K Dataset (ml-100k-zip). Working with this lite version has the benefit of less computational costs\n",
    "\n",
    "With a unix machine the dataset can be downloaded with the following code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "unzip:  cannot find or open ml-100k.zip, ml-100k.zip.zip or ml-100k.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip \n",
    "!unzip ml-100k.zip -d \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with a windows machine, please go to the website and download the 100k version and extract it to the subdirectory named \"data/ml-100k/\"\n",
    "\n",
    "Once you have downloaded and unzipped the file into a directory, you can create a DataFrame with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(150000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n",
      "La BD has 100000 ratings\n",
      "La BD has  943  users\n",
      "La BD has  1682  movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>M</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "      <td>4</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "      <td>4</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>M</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id         title  movie_id  rating release_date sex  age\n",
       "0      196  Kolya (1996)       242       3  24-Jan-1997   M   49\n",
       "1      305  Kolya (1996)       242       5  24-Jan-1997   M   23\n",
       "2        6  Kolya (1996)       242       4  24-Jan-1997   M   42\n",
       "3      234  Kolya (1996)       242       4  24-Jan-1997   M   60\n",
       "4       63  Kolya (1996)       242       3  24-Jan-1997   M   31"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NETFLIX REAL 50.000.000 usuaris and 100.000 items\n",
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Load Data set\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=r_cols)\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first three columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date']\n",
    "movies = pd.read_csv('ml-100k/u.item', sep='|', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "# Construcció del DataFrame\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "print(\"La BD has \"+ str(data.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", data.user_id.nunique(),\" users\")\n",
    "print(\"La BD has \", data.movie_id.nunique(), \" movies\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you explore the dataset in detail, you will see that it consists of:\n",
    "\n",
    "100,000 ratings from 943 users of 1682 movies. Ratings are from 1 to 5.\n",
    "Each user has rated at least 20 movies.\n",
    "Simple demographic info for the users (age, gender, occupation, zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Top movies ranking. \n",
    "The simplest way to show the ranking is by using the mean rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>They Made Me a Criminal (1939)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marlene Dietrich: Shadow and Light (1996)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saint of Fort Washington, The (1993)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Someone Else's America (1995)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Kid (1997)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Great Day in Harlem, A (1994)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aiqing wansui (1994)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santa with Muscles (1996)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prefontaine (1997)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entertaining Angels: The Dorothy Day Story (1996)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   mean_rating\n",
       "title                                                         \n",
       "They Made Me a Criminal (1939)                             5.0\n",
       "Marlene Dietrich: Shadow and Light (1996)                  5.0\n",
       "Saint of Fort Washington, The (1993)                       5.0\n",
       "Someone Else's America (1995)                              5.0\n",
       "Star Kid (1997)                                            5.0\n",
       "Great Day in Harlem, A (1994)                              5.0\n",
       "Aiqing wansui (1994)                                       5.0\n",
       "Santa with Muscles (1996)                                  5.0\n",
       "Prefontaine (1997)                                         5.0\n",
       "Entertaining Angels: The Dorothy Day Story (1996)          5.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score = data.groupby(['title'])[['rating']].mean().rename(columns = {'rating': 'mean_rating'})\n",
    "mean_score.sort_values(by='mean_rating',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-error\" style = \"border-radius:10px;border-width:3px;border-color:darkred;font-family:Verdana,sans-serif;font-size:14px;\">\n",
    "What do you think about the output? </div><br>\n",
    "Now, let's show only ranking the mean rating but using only those movies with at least 20 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close Shave, A (1995)</th>\n",
       "      <td>4.491071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schindler's List (1993)</th>\n",
       "      <td>4.466443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wrong Trousers, The (1993)</th>\n",
       "      <td>4.466102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Casablanca (1942)</th>\n",
       "      <td>4.456790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wallace &amp; Gromit: The Best of Aardman Animation (1996)</th>\n",
       "      <td>4.447761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shawshank Redemption, The (1994)</th>\n",
       "      <td>4.445230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rear Window (1954)</th>\n",
       "      <td>4.387560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usual Suspects, The (1995)</th>\n",
       "      <td>4.385768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Wars (1977)</th>\n",
       "      <td>4.358491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 Angry Men (1957)</th>\n",
       "      <td>4.344000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_rating\n",
       "title                                                          \n",
       "Close Shave, A (1995)                                  4.491071\n",
       "Schindler's List (1993)                                4.466443\n",
       "Wrong Trousers, The (1993)                             4.466102\n",
       "Casablanca (1942)                                      4.456790\n",
       "Wallace & Gromit: The Best of Aardman Animation...     4.447761\n",
       "Shawshank Redemption, The (1994)                       4.445230\n",
       "Rear Window (1954)                                     4.387560\n",
       "Usual Suspects, The (1995)                             4.385768\n",
       "Star Wars (1977)                                       4.358491\n",
       "12 Angry Men (1957)                                    4.344000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = data.groupby('title').size()\n",
    "mean_score.loc[size>20].sort_values(by='mean_rating',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-error\" style = \"border-radius:10px;border-width:3px;border-color:darkred;font-family:Verdana,sans-serif;font-size:14px;\">\n",
    "Any other idea?<br>\n",
    "How can you improve it?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is other measures like the <b>Damped Means</b>.\n",
    "\n",
    "\n",
    "* <b>Problem:</b> There is low conficende with few ratings\n",
    "* <b>Solution:</b> Assume that, without evidence, everything is average.\n",
    "\n",
    "<br>\n",
    "$damped\\_Means = \\frac{\\sum_u r_{u,i} + k \\mu}{n +  k}$\n",
    "<br><br>$k$ controls the strength of the requiered evidence\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>damped_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Schindler's List (1993)</td>\n",
       "      <td>318</td>\n",
       "      <td>4.436034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Casablanca (1942)</td>\n",
       "      <td>483</td>\n",
       "      <td>4.420153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>64</td>\n",
       "      <td>4.413988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>Close Shave, A (1995)</td>\n",
       "      <td>408</td>\n",
       "      <td>4.412284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Wrong Trousers, The (1993)</td>\n",
       "      <td>169</td>\n",
       "      <td>4.392958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  movie_id  damped_mean\n",
       "333           Schindler's List (1993)       318     4.436034\n",
       "429                 Casablanca (1942)       483     4.420153\n",
       "332  Shawshank Redemption, The (1994)        64     4.413988\n",
       "559             Close Shave, A (1995)       408     4.412284\n",
       "347        Wrong Trousers, The (1993)       169     4.392958"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "mean_score_movies  = data.groupby('movie_id')[['rating']].mean().rename(columns = {'rating': 'mean_rating'}).reset_index()\n",
    "sum_ratings_movie = data.groupby('movie_id')[['rating']].sum().rename(columns = {'rating': 'num_ratings'}).reset_index()\n",
    "sum_ratings_movie['num_ratings_factor'] = sum_ratings_movie['num_ratings'] + k *(data['rating'].mean())\n",
    "\n",
    "count_ratings = data.groupby('movie_id')[['rating']].count().rename(columns = {'rating': 'count_rating'}).reset_index()\n",
    "count_ratings['count_rating_factor'] = count_ratings['count_rating'] + k\n",
    "\n",
    "ratings_damped = pd.merge(sum_ratings_movie,\n",
    "                         count_ratings[['movie_id','count_rating','count_rating_factor']],\n",
    "                         on=['movie_id'],how='left')\n",
    "\n",
    "ratings_damped['damped_mean']=ratings_damped['num_ratings_factor']/ratings_damped['count_rating_factor']\n",
    "\n",
    "ratings_mean_damped=pd.merge(data[['title','movie_id']].drop_duplicates(),\n",
    "                             ratings_damped[['movie_id','damped_mean']],\n",
    "                             on=['movie_id'],how='left')\n",
    "\n",
    "ratings_mean_damped = ratings_mean_damped.sort_values(by='damped_mean', ascending=False)\n",
    "ratings_mean_damped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ranking Cosiderations\n",
    "\n",
    "+ Confidence\n",
    " - How confident are we that this item is good?\n",
    " \n",
    "+ Risk tolerance\n",
    " - High-risk, high-reward\n",
    " - Conservative recommendations+\n",
    "\n",
    "+ Domain and business considerations\n",
    " - Age\n",
    " - System goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOTHER EXAMPLE DOMAIN CONSTRAINT: TIME\n",
    "\n",
    "<p><b>REDDIT:</b> Old stories are not interesting even though they might have a high net upvotes score! How does Reddit deal with this?</p>\n",
    "<br>\n",
    "$$log_{10}max( 1,| U -D | ) +  \\frac{sign(U-D)*t_{post}}{45000} $$ \n",
    "<br>\n",
    "where $U$ is the number of upvotes and $D$ is the number of downvotes. \n",
    "* In Reddit, time and votes were treated independently.\n",
    "* The Log term has a damping effect for votes. The idea is that votes 11 to 100 should have the same influence as votes 1 to 10. Obviously, a post with 1000 votes should be better than a post with 1 vote, but is a post with 2000 votes much better than the 1000 votes? The log decreases marginal values for later votes.\n",
    "* The sign(U-D) is useful to bury any negative items (as Reddit wants only to show the popular ones!)\n",
    "\n",
    "<p><b>HACKERS NEWS:</b> </p>\n",
    "\n",
    "$$ \\frac{(U - D  +1)^\\alpha}{(t_{now} - t_{post})^\\gamma} P $$\n",
    "\n",
    "* Numerator is related to popularity\n",
    "* Denominator is realted to the age factor with a gravity effect with the $\\gamma$ parameter\n",
    "* $P$ is a penalty term for each new\n",
    "\n",
    "![alt hackers](images/hackers.png)\n",
    "\n",
    "\n",
    "<h3>It was really famous and then it become to getting worse.</h3>\n",
    "![alt ![alt IMDB](images/zagat.png)\n",
    "](images/zagat.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Basic product association recommenders\n",
    "</h3><br> People who buy X also buy Y. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different items 171\n",
      "Number of rows  9835\n",
      "An example: ['pip fruit', 'yogurt', 'cream cheese ', 'meat spreads']\n"
     ]
    }
   ],
   "source": [
    "#Let's read a dataset which contains several market baskets lists\n",
    "\n",
    "# read data/grocieries.csv\n",
    "def union(a, b):\n",
    "    \"\"\" return the union of two lists \"\"\"\n",
    "    return list(set(a) | set(b))\n",
    "\n",
    "market_data = []\n",
    "cont = 0\n",
    "items = []\n",
    "with open(\"data/groceries.csv\") as f:\n",
    "    for l in f:\n",
    "        market_data.append(l.rstrip().split(','))\n",
    "        items = union(items,l.rstrip().split(','))\n",
    "\n",
    "print(\"Number of different items\", len(items))\n",
    "print(\"Number of rows \", len(market_data))\n",
    "\n",
    "\n",
    "print(\"An example:\", market_data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most simple ways to found association between product could be obtained as follows: $$score(Y|X) = \\frac{X \\ and \\ Y}{X}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which is the top associated product with \"yogurt\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_associated_products(product,N = 5):\n",
    "    d = {}\n",
    "    times = 0\n",
    "    for l in market_data:\n",
    "        if product in l:\n",
    "            times = times + 1\n",
    "            for i in l:\n",
    "                if i != product: \n",
    "                    if(i in d):\n",
    "                        d[i] += 1.0\n",
    "                    else:\n",
    "                        d[i] = 1.0\n",
    "\n",
    "    for k in d:\n",
    "        d[k] =   d[k] / times\n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.40160349854227406), ('other vegetables', 0.3112244897959184), ('rolls/buns', 0.24635568513119532)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.6133333333333333), ('other vegetables', 0.52), ('root vegetables', 0.41333333333333333)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.38636363636363635), ('other vegetables', 0.3409090909090909), ('tropical fruit', 0.20454545454545456)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rum\"?\n",
    "s = top_associated_products('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens? Is it a good measure? It has a problem with popular items...\n",
    "<br>\n",
    "Let's check this other formula:\n",
    "$$score(Y|X) = \\frac{ \\frac{X \\ and \\ Y}{X}} {  \\frac{!X \\ and \\ Y}{!X} }  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def top_associated_products2(product,N = 5):\n",
    "    d, d_not, d_yes = {}, {}, {}\n",
    "    d = defaultdict(lambda: 0, d)\n",
    "    d_not = defaultdict(lambda: 0, d_not)\n",
    "    times, times_not = 0, 0\n",
    "    for l in market_data:\n",
    "        if product in l:\n",
    "            times = times + 1\n",
    "            for i in l:\n",
    "                if i != product: \n",
    "                    if(i in d_yes):\n",
    "                        d_yes[i] += 1.0\n",
    "                    else:\n",
    "                        d_yes[i] = 1.0\n",
    "        else:\n",
    "            times_not = times_not + 1\n",
    "            for i in l:\n",
    "                if(i in d_not):\n",
    "                    d_not[i] += 1.0\n",
    "                else:\n",
    "                    d_not[i] = 1.0\n",
    "                        \n",
    "    for k in d_yes:\n",
    "        if(d_not[k] == 0):\n",
    "            d[k] = 0\n",
    "        else:\n",
    "            d[k] =  ( d_yes[k] *times_not) / (times * d_not[k])\n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kitchen utensil', 6.168367346938775), ('preservation products', 6.168367346938775), ('meat spreads', 4.626275510204081)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products2('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('decalcifier', 20.02051282051282), ('canned fruit', 18.590476190476192), ('organic products', 18.590476190476192)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products2('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('artif. sweetener', 14.834848484848484), ('specialty vegetables', 13.907670454545455), ('cooking chocolate', 9.271780303030303)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rum\"?\n",
    "s = top_associated_products2('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check this last formula:\n",
    "$$ score(Y|X) = \\frac{P(X \\ and \\ Y)}{P(X)P(Y) }   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_associated_products3(product,N = 5):\n",
    "    d , times = {}, {}\n",
    "    d = defaultdict(lambda: 0, d)\n",
    "    times = defaultdict(lambda: 0, times)\n",
    "    for l in market_data:\n",
    "        for item in l:\n",
    "            if item in times: #already exist\n",
    "                times[item] += 1\n",
    "            else:\n",
    "                times[item] =1\n",
    "        if product in l:\n",
    "            for i in l:\n",
    "                if i != product: \n",
    "                    if(i in d):\n",
    "                        d[i] += 1.0\n",
    "                    else:\n",
    "                        d[i] = 1.0\n",
    "                        \n",
    "    for k in d:\n",
    "        d[k] =  ( d[k] /len(market_data) ) / ((times[k]/len(market_data)) * times[product] /(len(market_data)))\n",
    "        \n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('baby food', 7.168367346938775), ('kitchen utensil', 3.5841836734693877), ('preservation products', 3.5841836734693877)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products3('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('decalcifier', 17.484444444444446), ('canned fruit', 16.391666666666666), ('organic products', 16.391666666666666)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products3('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('artif. sweetener', 13.970170454545455), ('specialty vegetables', 13.148395721925132), ('cooking chocolate', 8.940909090909091)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products3('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('finished products', 153.671875), ('soups', 146.7910447761194), ('cake bar', 75.65384615384615)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products3('baby food',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APRIORI Algorithm\n",
    "Typically, association rules are considered interesting if they satisfy both a minimum support threshold and a minimum confidence threshold\n",
    "\n",
    "![alt apriori](images/apriori.png)\n",
    "\n",
    "<b>Apriori principle</b>: Any subset of a frequent itemset must be frequent\n",
    "\n",
    "> Step 1: Find the frequent itemsset: the set of items that have minimum support.\n",
    "> -  A subset of a frequent itemset must also be a frequent itemset  i.e. if {1,2} is a frequent itemset, both {1} and {2} should be a frequent itemset\n",
    "> - Iteratively find frequent itemsets with cardinality from 1 to k (k-itemset)\n",
    "\n",
    "> Step 2: Use the frequent itemsets to generate association rules\n",
    "\n",
    "![alt apriori2](images/apriori2.png)\n",
    "\n",
    "Reference : <a href=\"http://www-cgi.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ngm/15-721/summaries/12.pdf\" >Fast algorithms for mining association rules</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Homework for those with low python skills -> Implement Apriori Method "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
